{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "1. Data Preparation\n",
    "   - Load the data\n",
    "   - Split into features and target\n",
    "   - Create train/test split\n",
    "\n",
    "2. Define Evaluation Metrics\n",
    "   - Accuracy, Precision, Recall, F1-score for win prediction\n",
    "   - Mean Absolute Error, Mean Squared Error for score prediction\n",
    "\n",
    "3. Model Comparison (for win prediction)\n",
    "   - Logistic Regression\n",
    "   - Random Forest\n",
    "   - Gradient Boosting (e.g., XGBoost)\n",
    "   - Support Vector Machines\n",
    "\n",
    "4. Model Comparison (for score prediction)\n",
    "   - Linear Regression\n",
    "   - Decision Trees\n",
    "   - Random Forest\n",
    "   - Gradient Boosting\n",
    "\n",
    "5. Cross-Validation\n",
    "   - Implement k-fold cross-validation for each model\n",
    "\n",
    "6. Hyperparameter Tuning\n",
    "   - Use GridSearchCV or RandomizedSearchCV for best models\n",
    "\n",
    "7. Final Model Selection\n",
    "   - Choose the best model based on cross-validation results\n",
    "   - Evaluate on the test set\n",
    "\n",
    "8. Save Best Models\n",
    "   - Save the best models and their corresponding scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.visualization.distribution_plots import visualize_null_values\n",
    "\n",
    "# Add the project root to the Python path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_db_path = '../data/04_features/features_teams.db'\n",
    "conn = sqlite3.connect(target_db_path)\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df_all_years = pd.read_sql_query(\"SELECT * FROM features_teams\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_all_years = pd.read_parquet('../data/03_processed/preprocessed_all_years.parquet')\n",
    "df_2016_plus = pd.read_parquet('../data/03_processed/preprocessed_2016_plus.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target_column, drop_columns=None, test_size=0.2, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the data into train, validation, and test sets based on years.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame\n",
    "    target_column (str): The name of the target column\n",
    "    drop_columns (list): List of column names to drop from features. If None, use all columns except target and 'season'\n",
    "    test_size (float): Proportion of data to use for test set\n",
    "    val_size (float): Proportion of non-test data to use for validation set\n",
    "    random_state (int): Random state for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort the DataFrame by year to ensure chronological order\n",
    "    df = df.sort_values('year')\n",
    "    \n",
    "    # Define columns to drop\n",
    "    if drop_columns is None:\n",
    "        drop_columns = []\n",
    "    drop_columns = set(drop_columns + [target_column, 'year'])\n",
    "    \n",
    "    # Select feature columns (all columns except those in drop_columns)\n",
    "    feature_columns = [col for col in df.columns if col not in drop_columns]\n",
    "    \n",
    "    # Split features (X) and target (y)\n",
    "    X = df[feature_columns]\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Get unique years\n",
    "    years = df['year'].unique()\n",
    "    \n",
    "    # Calculate the number of years for test and validation\n",
    "    n_years = len(years)\n",
    "    n_test_years = max(1, int(n_years * test_size))\n",
    "    n_val_years = max(1, int((n_years - n_test_years) * val_size))\n",
    "    \n",
    "    # Split years into train, validation, and test\n",
    "    test_years = years[-n_test_years:]\n",
    "    val_years = years[-(n_test_years + n_val_years):-n_test_years]\n",
    "    train_years = years[:-(n_test_years + n_val_years)]\n",
    "    \n",
    "    # Create masks for each split\n",
    "    test_mask = df['year'].isin(test_years)\n",
    "    val_mask = df['year'].isin(val_years)\n",
    "    train_mask = df['year'].isin(train_years)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    df_all_years[df_all_years['year'] < 2024],\n",
    "    target_column='win',\n",
    "    drop_columns=[\n",
    "        'season_type',\n",
    "        'team_id',\n",
    "        'opponent_id',\n",
    "        'team_conference',\n",
    "        'opponent_conference',\n",
    "        'start_date'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.  Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'logistic_regression__C': 0.01, 'logistic_regression__penalty': 'l2', 'logistic_regression__solver': 'lbfgs', 'poly__degree': 1}\n",
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      1485\n",
      "           1       0.68      0.68      0.68      1485\n",
      "\n",
      "    accuracy                           0.68      2970\n",
      "   macro avg       0.68      0.68      0.68      2970\n",
      "weighted avg       0.68      0.68      0.68      2970\n",
      "\n",
      "Training Accuracy: 0.6849\n",
      "Validation Accuracy: 0.6805\n",
      "Test Accuracy: 0.6696\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "Feature 'is_home': 0.5039\n",
      "Feature 'points_allowed_last_3': 0.2823\n",
      "Feature 'points_scored_last_3': 0.2387\n",
      "Feature 'conference_game': 0.2068\n",
      "Feature 'rushingAttempts_last_3': 0.1565\n",
      "Feature 'win_rate_last_10': 0.1515\n",
      "Feature 'yardsPerRushAttempt_last_3': 0.1037\n",
      "Feature 'win_rate_last_3': 0.1030\n",
      "Feature 'rushingYards_last_3': 0.1027\n",
      "Feature 'offense_line_yards_last_10': 0.1004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_improved_logistic_regression_model(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Create a pipeline with more steps and options\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('logistic_regression', LogisticRegression(random_state=42, max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'poly__degree': [1],\n",
    "        'logistic_regression__C': [0.01, 0.1, 1, 10],\n",
    "        'logistic_regression__penalty': ['l2'],\n",
    "        'logistic_regression__solver': ['lbfgs']\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = best_model.predict(X_train)\n",
    "    val_predictions = best_model.predict(X_val)\n",
    "    test_predictions = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = abs(best_model.named_steps['logistic_regression'].coef_[0])\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Print top 10 feature importances\n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    for name, importance in sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"Feature '{name}': {importance:.4f}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Usage\n",
    "logistic_model = create_improved_logistic_regression_model(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63      1485\n",
      "           1       0.64      0.76      0.69      1485\n",
      "\n",
      "    accuracy                           0.66      2970\n",
      "   macro avg       0.67      0.66      0.66      2970\n",
      "weighted avg       0.67      0.66      0.66      2970\n",
      "\n",
      "Training Accuracy: 0.7113\n",
      "Validation Accuracy: 0.6646\n",
      "Test Accuracy: 0.6641\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "Feature 'is_home': 0.1050\n",
      "Feature 'win_rate_last_10': 0.0623\n",
      "Feature 'win_rate_last_5': 0.0568\n",
      "Feature 'points_allowed_last_3': 0.0473\n",
      "Feature 'win_rate_last_3': 0.0427\n",
      "Feature 'points_scored_last_3': 0.0368\n",
      "Feature 'win_rate_last_1': 0.0311\n",
      "Feature 'offense_success_rate_last_10': 0.0227\n",
      "Feature 'points_allowed_last_1': 0.0174\n",
      "Feature 'defense_ppa_last_10': 0.0160\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_lightweight_random_forest(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Create a pipeline with reduced complexity\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Handle null values\n",
    "        ('scaler', StandardScaler()),  # Scale features\n",
    "        ('rf', RandomForestClassifier(n_estimators=1000, max_depth=6, random_state=42))  # Reduced parameters\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = pipeline.predict(X_train)\n",
    "    val_predictions = pipeline.predict(X_val)\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Feature importance (top 10)\n",
    "    feature_importance = pipeline.named_steps['rf'].feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    for name, importance in sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"Feature '{name}': {importance:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Usage\n",
    "forest_model = create_lightweight_random_forest(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:00:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65      1485\n",
      "           1       0.65      0.70      0.68      1485\n",
      "\n",
      "    accuracy                           0.66      2970\n",
      "   macro avg       0.67      0.66      0.66      2970\n",
      "weighted avg       0.67      0.66      0.66      2970\n",
      "\n",
      "Training Accuracy: 0.9181\n",
      "Validation Accuracy: 0.6646\n",
      "Test Accuracy: 0.6533\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "Feature 'win_rate_last_5': 0.0683\n",
      "Feature 'is_home': 0.0577\n",
      "Feature 'win_rate_last_10': 0.0469\n",
      "Feature 'conference_game': 0.0177\n",
      "Feature 'points_allowed_last_3': 0.0134\n",
      "Feature 'offense_success_rate_last_10': 0.0118\n",
      "Feature 'neutral_site': 0.0113\n",
      "Feature 'win_rate_last_1': 0.0111\n",
      "Feature 'points_scored_last_3': 0.0111\n",
      "Feature 'win_rate_last_3': 0.0108\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_xgboost_model(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Handle null values\n",
    "        ('scaler', StandardScaler()),  # Scale features\n",
    "        ('xgb', XGBClassifier(\n",
    "            n_estimators=500,  # Number of boosting rounds\n",
    "            max_depth=4,       # Maximum tree depth\n",
    "            learning_rate=0.1, # Learning rate\n",
    "            subsample=0.8,     # Subsample ratio of the training instances\n",
    "            colsample_bytree=0.8, # Subsample ratio of columns when constructing each tree\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,  # Avoid warning about label encoder\n",
    "            eval_metric='logloss'     # Evaluation metric\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = pipeline.predict(X_train)\n",
    "    val_predictions = pipeline.predict(X_val)\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Feature importance (top 10)\n",
    "    feature_importance = pipeline.named_steps['xgb'].feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    for name, importance in sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"Feature '{name}': {importance:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Usage\n",
    "xgboost_model = create_xgboost_model(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year  week  team_id              team  opponent_id            opponent  \\\n",
      "9890   2024     2      130          Michigan          251               Texas   \n",
      "10025  2024     2      264        Washington         2199    Eastern Michigan   \n",
      "10149  2024     2       97        Louisville           55  Jacksonville State   \n",
      "9902   2024     2      201          Oklahoma          248             Houston   \n",
      "10156  2024     2      228           Clemson         2026   Appalachian State   \n",
      "...     ...   ...      ...               ...          ...                 ...   \n",
      "20526  2024     2     2184          Duquesne          103      Boston College   \n",
      "20393  2024     2     2710  Western Illinois           84             Indiana   \n",
      "20266  2024     2     2377           McNeese          245           Texas A&M   \n",
      "20276  2024     2     2016      Alcorn State          238          Vanderbilt   \n",
      "20643  2024     2      399            Albany          277       West Virginia   \n",
      "\n",
      "       logistic_win_probability  forest_win_probability  \\\n",
      "9890                   0.944460                0.774697   \n",
      "10025                  0.867217                0.674921   \n",
      "10149                  0.904554                0.746354   \n",
      "9902                   0.875887                0.711607   \n",
      "10156                  0.748005                0.636100   \n",
      "...                         ...                     ...   \n",
      "20526                  0.138757                0.123160   \n",
      "20393                  0.052594                0.126094   \n",
      "20266                  0.088348                0.109292   \n",
      "20276                  0.074923                0.114477   \n",
      "20643                  0.121412                0.122485   \n",
      "\n",
      "       xgboost_win_probability  avg_win_probability  \n",
      "9890                  0.988324             0.902494  \n",
      "10025                 0.969675             0.837271  \n",
      "10149                 0.957064             0.869324  \n",
      "9902                  0.953908             0.847134  \n",
      "10156                 0.948825             0.777643  \n",
      "...                        ...                  ...  \n",
      "20526                 0.011861             0.091259  \n",
      "20393                 0.010592             0.063093  \n",
      "20266                 0.008425             0.068689  \n",
      "20276                 0.005047             0.064816  \n",
      "20643                 0.004128             0.082675  \n",
      "\n",
      "[96 rows x 10 columns]\n",
      "Predictions saved to: ../models/win_probability/prediction_2024_2.parquet\n"
     ]
    }
   ],
   "source": [
    "from src.utils.team_pairs import get_team_pairs\n",
    "\n",
    "# Get team pairs\n",
    "team_pairs = dict(get_team_pairs())\n",
    "\n",
    "# Filter the data for 2024 week 2 games\n",
    "df_2024_week2 = df_all_years[(df_all_years['year'] == 2024) & (df_all_years['week'] == 2)]\n",
    "\n",
    "# Prepare the features for prediction\n",
    "X_predict = df_2024_week2.drop(['win', 'year', 'week', 'season_type', 'team_id', 'opponent_id', 'team_conference', 'opponent_conference', 'start_date'], axis=1)\n",
    "\n",
    "# Ensure X_predict has the same columns as X_train\n",
    "missing_cols = set(X_train.columns) - set(X_predict.columns)\n",
    "for col in missing_cols:\n",
    "    X_predict[col] = 0\n",
    "\n",
    "X_predict = X_predict[X_train.columns]\n",
    "\n",
    "# Predict probabilities for 2024 week 2 games using all three models\n",
    "logistic_probabilities = logistic_model.predict_proba(X_predict)[:, 1]\n",
    "forest_probabilities = forest_model.predict_proba(X_predict)[:, 1]\n",
    "xgboost_probabilities = xgboost_model.predict_proba(X_predict)[:, 1]\n",
    "\n",
    "# Create the result DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'year': df_2024_week2['year'],\n",
    "    'week': df_2024_week2['week'],\n",
    "    'team_id': df_2024_week2['team_id'],\n",
    "    'team': df_2024_week2['team_id'].map(team_pairs),\n",
    "    'opponent_id': df_2024_week2['opponent_id'],\n",
    "    'opponent': df_2024_week2['opponent_id'].map(team_pairs),\n",
    "    'logistic_win_probability': logistic_probabilities,\n",
    "    'forest_win_probability': forest_probabilities,\n",
    "    'xgboost_win_probability': xgboost_probabilities,\n",
    "    'avg_win_probability': (logistic_probabilities + forest_probabilities + xgboost_probabilities) / 3\n",
    "})\n",
    "\n",
    "# Sort by xgboost win probability in descending order\n",
    "result_df = result_df.sort_values('xgboost_win_probability', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)\n",
    "\n",
    "# Save the result as a parquet file\n",
    "output_dir = '../models/win_probability'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = f'{output_dir}/prediction_{df_2024_week2[\"year\"].iloc[0]}_{df_2024_week2[\"week\"].iloc[0]}.parquet'\n",
    "result_df.to_parquet(output_file, index=False)\n",
    "\n",
    "print(f\"Predictions saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "college_football_predictor",
   "language": "python",
   "name": "college_football_predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
