{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "1. Data Preparation\n",
    "   - Load the data\n",
    "   - Split into features and target\n",
    "   - Create train/test split\n",
    "\n",
    "2. Define Evaluation Metrics\n",
    "   - Accuracy, Precision, Recall, F1-score for win prediction\n",
    "   - Mean Absolute Error, Mean Squared Error for score prediction\n",
    "\n",
    "3. Model Comparison (for win prediction)\n",
    "   - Logistic Regression\n",
    "   - Decision Trees\n",
    "   - Random Forest\n",
    "   - Gradient Boosting (e.g., XGBoost)\n",
    "   - Support Vector Machines\n",
    "\n",
    "4. Model Comparison (for score prediction)\n",
    "   - Linear Regression\n",
    "   - Decision Trees\n",
    "   - Random Forest\n",
    "   - Gradient Boosting\n",
    "\n",
    "5. Cross-Validation\n",
    "   - Implement k-fold cross-validation for each model\n",
    "\n",
    "6. Hyperparameter Tuning\n",
    "   - Use GridSearchCV or RandomizedSearchCV for best models\n",
    "\n",
    "7. Final Model Selection\n",
    "   - Choose the best model based on cross-validation results\n",
    "   - Evaluate on the test set\n",
    "\n",
    "8. Save Best Models\n",
    "   - Save the best models and their corresponding scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add the project root to the Python path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_all_years = pd.read_parquet('../data/03_processed/preprocessed_all_years.parquet')\n",
    "df_2016_plus = pd.read_parquet('../data/03_processed/preprocessed_2016_plus.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target_column, drop_columns=None, test_size=0.2, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the data into train, validation, and test sets based on seasons.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame\n",
    "    target_column (str): The name of the target column\n",
    "    drop_columns (list): List of column names to drop from features. If None, use all columns except target and 'season'\n",
    "    test_size (float): Proportion of data to use for test set\n",
    "    val_size (float): Proportion of non-test data to use for validation set\n",
    "    random_state (int): Random state for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort the DataFrame by season to ensure chronological order\n",
    "    df = df.sort_values('season')\n",
    "    \n",
    "    # Define columns to drop\n",
    "    if drop_columns is None:\n",
    "        drop_columns = []\n",
    "    drop_columns = set(drop_columns + [target_column, 'season'])\n",
    "    \n",
    "    # Select feature columns (all columns except those in drop_columns)\n",
    "    feature_columns = [col for col in df.columns if col not in drop_columns]\n",
    "    \n",
    "    # Split features (X) and target (y)\n",
    "    X = df[feature_columns]\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Get unique seasons\n",
    "    seasons = df['season'].unique()\n",
    "    \n",
    "    # Calculate the number of seasons for test and validation\n",
    "    n_seasons = len(seasons)\n",
    "    n_test_seasons = max(1, int(n_seasons * test_size))\n",
    "    n_val_seasons = max(1, int((n_seasons - n_test_seasons) * val_size))\n",
    "    \n",
    "    # Split seasons into train, validation, and test\n",
    "    test_seasons = seasons[-n_test_seasons:]\n",
    "    val_seasons = seasons[-(n_test_seasons + n_val_seasons):-n_test_seasons]\n",
    "    train_seasons = seasons[:-(n_test_seasons + n_val_seasons)]\n",
    "    \n",
    "    # Create masks for each split\n",
    "    test_mask = df['season'].isin(test_seasons)\n",
    "    val_mask = df['season'].isin(val_seasons)\n",
    "    train_mask = df['season'].isin(train_seasons)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    df_all_years,\n",
    "    target_column='win',\n",
    "    drop_columns=[\n",
    "        'season_type',\n",
    "        'team_id',\n",
    "        'opponent_id',\n",
    "        'team_conference',\n",
    "        'opponent_conference',\n",
    "        'start_date'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.  Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_improved_logistic_regression_model(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Create a pipeline with more steps and options\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('logistic_regression', LogisticRegression(random_state=42, max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'poly__degree': [1, 2],\n",
    "        'logistic_regression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'logistic_regression__penalty': ['l1', 'l2'],\n",
    "        'logistic_regression__solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = best_model.predict(X_train)\n",
    "    val_predictions = best_model.predict(X_val)\n",
    "    test_predictions = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Usage\n",
    "improved_model = create_improved_logistic_regression_model(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "college_football_predictor",
   "language": "python",
   "name": "college_football_predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
