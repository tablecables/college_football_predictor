{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "1. Data Preparation\n",
    "   - Load the data\n",
    "   - Split into features and target\n",
    "   - Create train/test split\n",
    "\n",
    "2. Define Evaluation Metrics\n",
    "   - Accuracy, Precision, Recall, F1-score for win prediction\n",
    "   - Mean Absolute Error, Mean Squared Error for score prediction\n",
    "\n",
    "3. Model Comparison (for win prediction)\n",
    "   - Logistic Regression\n",
    "   - Random Forest\n",
    "   - Gradient Boosting (e.g., XGBoost)\n",
    "   - Support Vector Machines\n",
    "\n",
    "4. Model Comparison (for score prediction)\n",
    "   - Linear Regression\n",
    "   - Decision Trees\n",
    "   - Random Forest\n",
    "   - Gradient Boosting\n",
    "\n",
    "5. Cross-Validation\n",
    "   - Implement k-fold cross-validation for each model\n",
    "\n",
    "6. Hyperparameter Tuning\n",
    "   - Use GridSearchCV or RandomizedSearchCV for best models\n",
    "\n",
    "7. Final Model Selection\n",
    "   - Choose the best model based on cross-validation results\n",
    "   - Evaluate on the test set\n",
    "\n",
    "8. Save Best Models\n",
    "   - Save the best models and their corresponding scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add the project root to the Python path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.visualization.distribution_plots import visualize_null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.   Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_db_path = '../data/04_features/features_teams.db'\n",
    "conn = sqlite3.connect(target_db_path)\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "df_all_years = pd.read_sql_query(\"SELECT * FROM features_teams\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'week', 'start_date', 'is_home', 'season_type', 'neutral_site',\n",
       "       'conference_game', 'team_id', 'opponent_id', 'team_conference',\n",
       "       ...\n",
       "       'defense_standard_downs_success_rate_last_3',\n",
       "       'defense_standard_downs_success_rate_last_10', 'win_rate_last_1',\n",
       "       'win_rate_last_3', 'win_rate_last_5', 'win_rate_last_10',\n",
       "       'points_scored_last_1', 'points_allowed_last_1', 'points_scored_last_3',\n",
       "       'points_allowed_last_3'],\n",
       "      dtype='object', length=180)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_years.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target_column, drop_columns=None, test_size=0.2, val_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the data into train, validation, and test sets based on years.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame\n",
    "    target_column (str): The name of the target column\n",
    "    drop_columns (list): List of column names to drop from features. If None, use all columns except target and 'season'\n",
    "    test_size (float): Proportion of data to use for test set\n",
    "    val_size (float): Proportion of non-test data to use for validation set\n",
    "    random_state (int): Random state for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort the DataFrame by year to ensure chronological order\n",
    "    df = df.sort_values('year')\n",
    "    \n",
    "    # Define columns to drop\n",
    "    if drop_columns is None:\n",
    "        drop_columns = []\n",
    "    drop_columns = set(drop_columns + [target_column, 'year'])\n",
    "    \n",
    "    # Select feature columns (all columns except those in drop_columns)\n",
    "    feature_columns = [col for col in df.columns if col not in drop_columns]\n",
    "    \n",
    "    # Split features (X) and target (y)\n",
    "    X = df[feature_columns]\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Get unique years\n",
    "    years = df['year'].unique()\n",
    "    \n",
    "    # Calculate the number of years for test and validation\n",
    "    n_years = len(years)\n",
    "    n_test_years = max(1, int(n_years * test_size))\n",
    "    n_val_years = max(1, int((n_years - n_test_years) * val_size))\n",
    "    \n",
    "    # Split years into train, validation, and test\n",
    "    test_years = years[-n_test_years:]\n",
    "    val_years = years[-(n_test_years + n_val_years):-n_test_years]\n",
    "    train_years = years[:-(n_test_years + n_val_years)]\n",
    "    \n",
    "    # Create masks for each split\n",
    "    test_mask = df['year'].isin(test_years)\n",
    "    val_mask = df['year'].isin(val_years)\n",
    "    train_mask = df['year'].isin(train_years)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[val_mask], y[val_mask]\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    df_all_years[df_all_years['year'] < 2024],\n",
    "    target_column='win',\n",
    "    drop_columns=[\n",
    "        'season_type',\n",
    "        'team_id',\n",
    "        'opponent_id',\n",
    "        'team_conference',\n",
    "        'opponent_conference',\n",
    "        'start_date',\n",
    "        'venue_id'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.  Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['avg_line_spread' 'team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'logistic_regression__C': 0.01, 'logistic_regression__penalty': 'l2', 'logistic_regression__solver': 'lbfgs', 'poly__degree': 1}\n",
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.77      0.77      1485\n",
      "         1.0       0.77      0.76      0.77      1485\n",
      "\n",
      "    accuracy                           0.77      2970\n",
      "   macro avg       0.77      0.77      0.77      2970\n",
      "weighted avg       0.77      0.77      0.77      2970\n",
      "\n",
      "Training Accuracy: 0.7612\n",
      "Validation Accuracy: 0.7687\n",
      "Test Accuracy: 0.7479\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "Feature 'opponent_pregame_elo': 0.7802\n",
      "Feature 'team_pregame_elo': 0.5877\n",
      "Feature 'is_home': 0.4240\n",
      "Feature 'avg_line_spread': 0.3599\n",
      "Feature 'opponent_recruiting_rank': 0.3023\n",
      "Feature 'team_recruiting_rank': 0.2733\n",
      "Feature 'firstDowns_last_3': 0.1327\n",
      "Feature 'points_allowed_last_3': 0.1248\n",
      "Feature 'offense_rushing_plays_ppa_last_3': 0.0808\n",
      "Feature 'defense_standard_downs_explosiveness_last_3': 0.0771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_improved_logistic_regression_model(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Create a pipeline with more steps and options\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        ('logistic_regression', LogisticRegression(random_state=42, max_iter=1000))\n",
    "    ])\n",
    "    \n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'poly__degree': [1],\n",
    "        'logistic_regression__C': [0.01, 0.1, 1, 10],\n",
    "        'logistic_regression__penalty': ['l2'],\n",
    "        'logistic_regression__solver': ['lbfgs']\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = best_model.predict(X_train)\n",
    "    val_predictions = best_model.predict(X_val)\n",
    "    test_predictions = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importances = abs(best_model.named_steps['logistic_regression'].coef_[0])\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Print top 10 feature importances\n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    for name, importance in sorted(zip(feature_names, feature_importances), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"Feature '{name}': {importance:.4f}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Usage\n",
    "logistic_model = create_improved_logistic_regression_model(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.74      0.75      1485\n",
      "         1.0       0.75      0.78      0.77      1485\n",
      "\n",
      "    accuracy                           0.76      2970\n",
      "   macro avg       0.76      0.76      0.76      2970\n",
      "weighted avg       0.76      0.76      0.76      2970\n",
      "\n",
      "Training Accuracy: 0.7795\n",
      "Validation Accuracy: 0.7603\n",
      "Test Accuracy: 0.7446\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "Feature 'opponent_pregame_elo': 0.1226\n",
      "Feature 'opponent_recruiting_rank': 0.0813\n",
      "Feature 'team_pregame_elo': 0.0805\n",
      "Feature 'opponent_recruiting_points': 0.0657\n",
      "Feature 'is_home': 0.0613\n",
      "Feature 'avg_line_spread': 0.0548\n",
      "Feature 'team_recruiting_rank': 0.0526\n",
      "Feature 'team_recruiting_points': 0.0355\n",
      "Feature 'win_rate_last_10': 0.0345\n",
      "Feature 'win_rate_last_5': 0.0307\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_lightweight_random_forest(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    # Create a pipeline with reduced complexity\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Handle null values\n",
    "        ('scaler', StandardScaler()),  # Scale features\n",
    "        ('rf', RandomForestClassifier(n_estimators=1000, max_depth=6, random_state=42))  # Reduced parameters\n",
    "    ])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    train_predictions = pipeline.predict(X_train)\n",
    "    val_predictions = pipeline.predict(X_val)\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Feature importance (top 10)\n",
    "    feature_importance = pipeline.named_steps['rf'].feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    print(\"\\nTop 10 Feature Importances:\")\n",
    "    for name, importance in sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"Feature '{name}': {importance:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Usage\n",
    "forest_model = create_lightweight_random_forest(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n",
      "/Users/colingaffney/repos/personal-projects/college_football_predictor/venv/lib/python3.12/site-packages/sklearn/impute/_base.py:598: UserWarning: Skipping features without any observed values: ['team_talent' 'opponent_talent']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'xgb__subsample': 0.8, 'xgb__n_estimators': 500, 'xgb__max_depth': 5, 'xgb__learning_rate': 0.01, 'xgb__colsample_bytree': 0.9}\n",
      "\n",
      "Training Accuracy: 0.8040304182509506\n",
      "Validation Accuracy: 0.7673400673400673\n",
      "Test Accuracy: 0.7443463872035301\n",
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.76      0.77      1485\n",
      "         1.0       0.77      0.77      0.77      1485\n",
      "\n",
      "    accuracy                           0.77      2970\n",
      "   macro avg       0.77      0.77      0.77      2970\n",
      "weighted avg       0.77      0.77      0.77      2970\n",
      "\n",
      "\n",
      "Top 10 Important Features:\n",
      "team_pregame_elo: 0.0384\n",
      "is_home: 0.0354\n",
      "opponent_pregame_elo: 0.0320\n",
      "team_recruiting_rank: 0.0281\n",
      "opponent_recruiting_rank: 0.0274\n",
      "win_rate_last_5: 0.0237\n",
      "win_rate_last_1: 0.0201\n",
      "avg_line_spread: 0.0189\n",
      "win_rate_last_10: 0.0174\n",
      "points_allowed_last_3: 0.0111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def create_improved_xgboost_model(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('xgb', XGBClassifier(random_state=42, eval_metric='logloss'))\n",
    "    ])\n",
    "    \n",
    "    param_grid = {\n",
    "        'xgb__n_estimators': [500, 1000, 1500],\n",
    "        'xgb__max_depth': [3, 4, 5, 6],\n",
    "        'xgb__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'xgb__subsample': [0.8, 0.9, 1.0],\n",
    "        'xgb__colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    \n",
    "    grid_search = RandomizedSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, n_iter=20, random_state=42)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    print(\"\\nTraining Accuracy:\", train_accuracy)\n",
    "    print(\"Validation Accuracy:\", val_accuracy)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "    \n",
    "    print(\"\\nValidation Set Classification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = best_model.named_steps['xgb'].feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nTop 10 Important Features:\")\n",
    "    for feature, importance in sorted_features[:10]:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Usage\n",
    "xgboost_model = create_improved_xgboost_model(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yq/dnnn56yn2l34mgnc3mc_8kyr0000gn/T/ipykernel_27323/1226317420.py:63: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_result = result_df.groupby('pair').apply(process_team_pair).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  week  home_id       home_team  away_id         away_team  \\\n",
      "279  2024     3     2633       Tennessee     2309        Kent State   \n",
      "231  2024     4      251           Texas     2433  Louisiana Monroe   \n",
      "208  2024     4      213      Penn State     2309        Kent State   \n",
      "197  2024     1      201        Oklahoma      218            Temple   \n",
      "85   2024     2       61         Georgia     2635    Tennessee Tech   \n",
      "..    ...   ...      ...             ...      ...               ...   \n",
      "237  2024     3      328      Utah State      254              Utah   \n",
      "217  2024     6      238      Vanderbilt      333           Alabama   \n",
      "133  2024     5      127  Michigan State      194        Ohio State   \n",
      "42   2024     5       26            UCLA     2483            Oregon   \n",
      "128  2024     7      113           UMass      142          Missouri   \n",
      "\n",
      "     win_probability  \n",
      "279         0.961099  \n",
      "231         0.960768  \n",
      "208         0.954529  \n",
      "197         0.951784  \n",
      "85          0.947258  \n",
      "..               ...  \n",
      "237         0.137453  \n",
      "217         0.133432  \n",
      "133         0.125888  \n",
      "42          0.095722  \n",
      "128         0.076041  \n",
      "\n",
      "[283 rows x 7 columns]\n",
      "Predictions saved to: ../models/win_probability/predictions_2024_3.parquet\n",
      "Models saved with timestamp: 20241011\n"
     ]
    }
   ],
   "source": [
    "from src.utils.team_pairs import get_team_pairs\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Get team pairs\n",
    "team_pairs = dict(get_team_pairs())\n",
    "\n",
    "# Filter the data for 2024 week 2 games\n",
    "df_2024_week2 = df_all_years[(df_all_years['year'] == 2024) & (df_all_years['week'].isin([1, 2, 3, 4, 5, 6, 7]))]\n",
    "\n",
    "# Prepare the features for prediction\n",
    "X_predict = df_2024_week2.drop(['win', 'year', 'week', 'season_type', 'team_id', 'opponent_id', 'team_conference', 'opponent_conference', 'start_date'], axis=1)\n",
    "\n",
    "# Ensure X_predict has the same columns as X_train\n",
    "missing_cols = set(X_train.columns) - set(X_predict.columns)\n",
    "for col in missing_cols:\n",
    "    X_predict[col] = 0\n",
    "\n",
    "X_predict = X_predict[X_train.columns]\n",
    "\n",
    "# Predict probabilities for 2024 week 2 games using all three models\n",
    "logistic_probabilities = logistic_model.predict_proba(X_predict)[:, 1]\n",
    "forest_probabilities = forest_model.predict_proba(X_predict)[:, 1]\n",
    "xgboost_probabilities = xgboost_model.predict_proba(X_predict)[:, 1]\n",
    "\n",
    "# Create the result DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'year': df_2024_week2['year'],\n",
    "    'week': df_2024_week2['week'],\n",
    "    'team_id': df_2024_week2['team_id'],\n",
    "    'team': df_2024_week2['team_id'].map(team_pairs),\n",
    "    'opponent_id': df_2024_week2['opponent_id'],\n",
    "    'opponent': df_2024_week2['opponent_id'].map(team_pairs),\n",
    "    'is_home': df_2024_week2['is_home'],\n",
    "    'logistic_win_probability': logistic_probabilities,\n",
    "    'forest_win_probability': forest_probabilities,\n",
    "    'xgboost_win_probability': xgboost_probabilities,\n",
    "    'win_probability': (logistic_probabilities + forest_probabilities + xgboost_probabilities) / 3\n",
    "})\n",
    "\n",
    "# Create a pair column\n",
    "result_df['pair'] = result_df.apply(lambda row: tuple(sorted([row['team_id'], row['opponent_id']])), axis=1)\n",
    "\n",
    "# Function to process predictions for a pair of teams\n",
    "def process_team_pair(group):\n",
    "    home_team = group[group['is_home'] == 1].iloc[0]\n",
    "    away_team = group[group['is_home'] == 0].iloc[0]\n",
    "    \n",
    "    win_prob = (home_team['win_probability'] + (1 - away_team['win_probability'])) / 2\n",
    "    \n",
    "    return pd.Series({\n",
    "        'year': home_team['year'],\n",
    "        'week': home_team['week'],\n",
    "        'home_id': home_team['team_id'],\n",
    "        'home_team': home_team['team'],\n",
    "        'away_id': away_team['team_id'],\n",
    "        'away_team': away_team['team'],\n",
    "        'win_probability': win_prob\n",
    "    })\n",
    "\n",
    "# Group by pair and apply the processing function\n",
    "final_result = result_df.groupby('pair').apply(process_team_pair).reset_index(drop=True)\n",
    "\n",
    "# Sort by home win probability in descending order\n",
    "final_result = final_result.sort_values('win_probability', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(final_result)\n",
    "\n",
    "# Save the result as a parquet file and models as joblib files\n",
    "output_dir = '../models/win_probability'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save prediction parquet file\n",
    "output_file = f'{output_dir}/predictions_{final_result[\"year\"].iloc[0]}_{final_result[\"week\"].iloc[0]}.parquet'\n",
    "final_result.to_parquet(output_file, index=False)\n",
    "\n",
    "# Save models\n",
    "# Generate date (without time)\n",
    "date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "joblib.dump(logistic_model, f'{output_dir}/logistic_{date}.joblib')\n",
    "joblib.dump(forest_model, f'{output_dir}/forest_{date}.joblib')\n",
    "joblib.dump(xgboost_model, f'{output_dir}/xgboost_{date}.joblib')\n",
    "\n",
    "print(f\"Predictions saved to: {output_file}\")\n",
    "print(f\"Models saved with timestamp: {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "college_football_predictor",
   "language": "python",
   "name": "college_football_predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
